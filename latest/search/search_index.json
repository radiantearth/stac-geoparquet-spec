{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"STAC GeoParquet Specification","text":""},{"location":"#overview","title":"Overview","text":"<p>This document specifies how to map a set of STAC Items into GeoParquet. It is directly inspired by the STAC GeoParquet library, but aims to provide guidance for anyone putting STAC data into GeoParquet.</p>"},{"location":"#use-cases","title":"Use cases","text":"<ul> <li>Provide a STAC GeoParquet that mirrors a static Collection as a way to query the whole dataset instead of reading every specific GeoJSON file.</li> <li>As an output format for STAC API responses that is more efficient than paging through thousands of pages of GeoJSON.</li> <li>Provide efficient access to specific fields of a STAC item, thanks to Parquet's columnar format.</li> </ul>"},{"location":"#guidelines","title":"Guidelines","text":"<p>Each row in the Parquet Dataset represents a single STAC item. Most all the fields in a STAC Item should be mapped to a column in GeoParquet. We embrace Parquet structures where possible, mapping from JSON into nested structures. We do pull the properties to the top level, so that it is easier to query and use them. The names of most of the fields should be the same in STAC and in GeoParquet.</p> Field GeoParquet Type Required Details type String Optional This is just needed for GeoJSON, so it is optional and not recommended to include in GeoParquet stac_extensions List of Strings Required This column is required, but can be empty if no STAC extensions were used id String Required Required, should be unique within each collection geometry Binary (WKB) Required For GeoParquet 1.0 this must be well-known Binary bbox Struct of Floats Required Can be a 4 or 6 value struct, depending on dimension of the data. It must conform to the \"Bounding Box Columns\" definition of GeoParquet 1.1. links List of Link structs Required See Link Struct for more info assets An Assets struct Required See Asset Struct for more info collection String Optional The ID of the collection this Item is a part of. See notes below on 'Collection' and 'Collection JSON' in the Parquet metadata property columns varies - Each property should use the relevant Parquet type, and be pulled out of the properties object to be a top-level Parquet field <ul> <li>Must be valid GeoParquet, with proper metadata. Ideally the geometry types are defined and as narrow as possible.</li> <li>Strongly recommend storing items that are mostly homogeneous (i.e. have the same fields). Parquet is a columnar format; storing items with many different fields will lead to an expanded parquet Schema with lots of empty data. In practice, this means storing a single collection or only collections with very similar item properties in a single stac-geoparquet dataset.</li> <li>Any field in 'properties' of the STAC item should be moved up to be a top-level field in the GeoParquet.</li> <li>STAC GeoParquet does not support properties that are named such that they collide with a top-level key.</li> <li>datetime columns should be stored as a native timestamp, not as a string</li> <li>The Collection JSON objects should be included in the Parquet metadata. See Collection JSON below.</li> <li>Any other properties that would be stored as GeoJSON in a STAC JSON Item (e.g. <code>proj:geometry</code>) should be stored as a binary column with WKB encoding. This simplifies the handling of collections with multiple geometry types.</li> </ul>"},{"location":"#link-struct","title":"Link Struct","text":"<p>The GeoParquet dataset can contain zero or more Link Structs. Each Link Struct has 2 required fields and 2 optional ones:</p> Field Name Type Description href string REQUIRED. The actual link in the format of an URL. Relative and absolute links are both allowed. rel string REQUIRED. Relationship between the current document and the linked document. See chapter \"Relation types\" for more information. type string Media type of the referenced entity. title string A human readable title to be used in rendered displays of the link. <p>See Link Object for more.</p>"},{"location":"#asset-struct","title":"Asset Struct","text":"<p>The GeoParquet dataset can contain zero or more Asset Structs. Each Asset Struct can have the following fields:</p> Field Name Type Description href string REQUIRED. URI to the asset object. Relative and absolute URI are both allowed. title string The displayed title for clients and users. description string A description of the Asset providing additional details, such as how it was processed or created. CommonMark 0.29 syntax MAY be used for rich text representation. type string Media type of the asset. See the common media types in the best practice doc for commonly used asset types. roles [string] The semantic roles of the asset, similar to the use of <code>rel</code> in links. <p>Each struct has each full asset key and object as a sub-struct, it's a direct mapping from the JSON to Parquet</p> <p>To take advantage of Parquet's columnar nature and compression, the assets should be uniform so they can be represented by a simple schema, which in turn means every item should probably come from the same STAC collection.</p> <p>See Asset Object for more.</p>"},{"location":"#parquet-metadata","title":"Parquet Metadata","text":"<p>stac-geoparquet uses Parquet File Metadata to store metadata about the dataset. All stac-geoparquet metadata is stored under the key <code>stac-geoparquet</code> in the parquet file metadata.</p> <p>See <code>example-metadata.json</code> for an example.</p> <p>A jsonschema schema file is provided for tools to validate against. Note that the json-schema for stac-geoparquet does not validate the <code>collection</code> object against the STAC json-schema. You'll need to validate that separately.</p> Field Name Type Description <code>version</code> string The stac-geoparquet metadata version. The stac-geoparquet version this dataset implements. <code>collections</code> Map A mapping from collection ID to STAC collection objects. <code>collection</code> STAC Collection object deprecated. Use <code>collections</code> instead. <p>Note that this metadata is distinct from the file metadata required by [geoparquet].</p>"},{"location":"#geoparquet-version","title":"Geoparquet Version","text":"<p>The field <code>version</code> stores the version of the stac-geoparquet specification the data complies with. Readers can use this field to understand what features and fields are available.</p> <p>Currently, the only allowed values are <code>\"1.1.0\"</code> and <code>\"1.0.0\"</code>.</p> <p>Note: early versions of this specification didn't include a <code>version</code> field. Readers aiming for maximum compatibility may attempt to read files without this key present, despite it being required from 1.0.0 onwards.</p>"},{"location":"#stac-collection-objects","title":"STAC Collection Objects","text":"<p>To make a stac-geoparquet file a fully self-contained representation, you can include STAC Collection JSON objects in the Parquet metadata under the <code>collections</code> key. This should be a mapping from Collection ID to Collection object. As usual, the ID used as the key of the mapping must match the ID in the Collection object.</p> <p>Because parquet is a columnar format and stores the union of all the fields from all the items, we recommend only storing STAC collections with the same or mostly the same fields in the same stac-geoparquet dataset. STAC collections with very different schemas should likely be distributed in separate stac-geoparquet datasets.</p>"},{"location":"#stac-collection-object","title":"STAC Collection Object","text":"<p>Version 1.0.0 of this specification included a singular <code>collection</code> field that stored a single STAC collection object. In version 1.1.0, this field is deprecated in favor of <code>collections</code>.</p>"},{"location":"#referencing-a-stac-geoparquet-collections-in-a-stac-collection-json","title":"Referencing a STAC Geoparquet Collections in a STAC Collection JSON","text":"<p>A common use case of stac-geoparquet is to create a mirror of a STAC collection. To refer to this mirror in the original collection, use an Asset Object at the collection level of the STAC JSON that includes the <code>application/vnd.apache.parquet</code> Media type and <code>collection-mirror</code> Role type to describe the function of the Geoparquet STAC Co For example:</p> Field Name Type Value href string s3://example/uri/to/file.parquet title string An example STAC GeoParquet. description string Example description. type string <code>application/vnd.apache.parquet</code> roles [string] [collection-mirror]* <p>*Note the IANA has not approved the new Media type <code>application/vnd.apache.parquet</code> yet, it's been submitted for approval.</p> <p>The description should ideally include details about the spatial partitioning method.</p>"},{"location":"#mapping-to-other-geospatial-data-formats","title":"Mapping to other geospatial data formats","text":"<p>The principles here can likely be used to map into other geospatial data formats (GeoPackage, FlatGeobuf, etc), but we embrace Parquet's nested 'structs' for some of the mappings, so other formats will need to do something different. The obvious thing to do is to dump JSON into those fields, but that's outside the scope of this document, and we recommend creating a general document for that.</p>"},{"location":"drawbacks/","title":"Drawbacks","text":"<p>Trying to represent STAC data in GeoParquet has some drawbacks.</p>"},{"location":"drawbacks/#unable-to-represent-undefined-values","title":"Unable to represent undefined values","text":"<p>Parquet is unable to represent the difference between undefined and null, and so is unable to perfectly round-trip STAC data with undefined values.</p> <p>In JSON a value can have one of three states: defined, undefined, or null. The <code>\"b\"</code> key in the next three examples illustrates this:</p> <p>Defined:</p> <pre><code>{\n  \"a\": 1,\n  \"b\": \"foo\"\n}\n</code></pre> <p>Undefined:</p> <pre><code>{\n  \"a\": 2\n}\n</code></pre> <p>Null:</p> <pre><code>{\n  \"a\": 3,\n  \"b\": null\n}\n</code></pre> <p>Because Parquet is a columnar format, it is only able to represent undefined at the column level. So if those three JSON items above were converted to Parquet, the column <code>\"b\"</code> would exist because it exists in the first and third item, and the second item would have <code>\"b\"</code> inferred as <code>null</code>:</p> a b 1 \"foo\" 2 null 3 null <p>Then when the second item is converted back to JSON, it will be returned as</p> <pre><code>{\n  \"a\": 2\n  \"b\": null\n}\n</code></pre> <p>which is not strictly equal to the input.</p>"},{"location":"schema/","title":"Schema considerations","text":"<p>A STAC Item is a JSON object to describe an external geospatial dataset. The STAC specification defines a common core, plus a variety of extensions. Additionally, STAC Items may include custom extensions outside the common ones. Crucially, the majority of the specified fields in the core spec and extensions define optional keys. Those keys often differ across STAC collections and may even differ within a single collection across items.</p> <p>STAC's flexibility is a blessing and a curse. The flexibility of schemaless JSON allows for very easy writing as each object can be dumped separately to JSON. Every item is allowed to have a different schema. And newer items are free to have a different schema than older items in the same collection. But this write-time flexibility makes it harder to read as there are no guarantees (outside STAC's few required fields) about what fields exist.</p> <p>Parquet is the complete opposite of JSON. Parquet has a strict schema that must be known before writing can start. This puts the burden of work onto the writer instead of the reader. Reading Parquet is very efficient because the file's metadata defines the exact schema of every record. This also enables use cases like reading specific columns that would not be possible without a strict schema.</p> <p>This conversion from schemaless to strict-schema is the difficult part of converting STAC from JSON to GeoParquet, especially for large input datasets like STAC that are often larger than memory.</p>"},{"location":"schema/#full-scan-over-input-data","title":"Full scan over input data","text":"<p>The most foolproof way to convert STAC JSON to GeoParquet is to perform a full scan over input data. This is done automatically by [<code>parse_stac_ndjson_to_arrow</code>][stac_geoparquet.arrow.parse_stac_ndjson_to_arrow] when a schema is not provided.</p> <p>This is time consuming as it requires two full passes over the input data: once to infer a common schema and again to actually write to Parquet (though items are never fully held in memory, allowing this process to scale).</p>"},{"location":"schema/#user-provided-schema","title":"User-provided schema","text":"<p>Alternatively, the user can pass in an Arrow schema themselves using the <code>schema</code> parameter of [<code>parse_stac_ndjson_to_arrow</code>][stac_geoparquet.arrow.parse_stac_ndjson_to_arrow]. This <code>schema</code> must match the on-disk schema of the the STAC JSON data.</p>"},{"location":"schema/#multiple-schemas-per-collection","title":"Multiple schemas per collection","text":"<p>It is also possible to write multiple Parquet files with STAC data where each Parquet file may have a different schema. This simplifies the conversion and writing process but makes reading and using the Parquet data harder.</p>"},{"location":"schema/#merging-data-with-schema-mismatch","title":"Merging data with schema mismatch","text":"<p>If you've created STAC GeoParquet data where the schema has updated, you can use [<code>pyarrow.concat_tables</code>][pyarrow.concat_tables] with <code>promote_options=\"permissive\"</code> to combine multiple STAC GeoParquet files.</p> <pre><code>import pyarrow as pa\nimport pyarrow.parquet as pq\n\ntable_1 = pq.read_table(\"stac1.parquet\")\ntable_2 = pq.read_table(\"stac2.parquet\")\ncombined_table = pa.concat_tables([table1, table2], promote_options=\"permissive\")\n</code></pre>"},{"location":"schema/#future-work","title":"Future work","text":"<p>Schema operations is an area where future work can improve reliability and ease of use of STAC GeoParquet.</p> <p>It's possible that in the future we could automatically infer an Arrow schema from the STAC specification's published JSON Schema files. If you're interested in this, open an issue and discuss.</p>"}]}